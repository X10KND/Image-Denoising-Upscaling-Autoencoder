{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q tensorflow==2.4.1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport time\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, losses\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.utils import plot_model\n\nfrom skimage.util import random_noise\nfrom skimage.filters import gaussian\nfrom skimage.transform import rescale, resize\nfrom skimage.metrics import mean_squared_error, peak_signal_noise_ratio, structural_similarity","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ffhq_path = \"../input/flickrfaceshq-dataset-ffhq/*\"\nceleba_path = \"../input/celeba-dataset/img_align_celeba/img_align_celeba/*\"\n\n#HEIGHT = 512\n#WIDTH = 512\nCHANNELS = 3\n\nFILTER = 64\n\nSCALE = 8\nksize = 3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = tf.keras.Input(shape=(None, None, CHANNELS))\n\nb1c1 = layers.Conv2D(FILTER // 8, (ksize, ksize), padding = \"same\", activation = \"relu\")(inputs)\nb1c2 = layers.Conv2D(FILTER // 8, (ksize, ksize), padding = \"same\", activation = \"relu\")(b1c1)\nb1c3 = layers.Conv2D(FILTER // 8, (ksize, ksize), padding = \"same\", activation = \"relu\")(b1c2)\nb1c4 = layers.Conv2D(FILTER // 8, (ksize, ksize), padding = \"same\", activation = \"relu\")(b1c3)\n\nmp1 = layers.MaxPool2D((2, 2))(b1c4)\n\nb2c1 = layers.Conv2D(FILTER // 4, (ksize, ksize), padding = \"same\", activation = \"relu\")(mp1)\nb2c2 = layers.Conv2D(FILTER // 4, (ksize, ksize), padding = \"same\", activation = \"relu\")(b2c1)\nb2c3 = layers.Conv2D(FILTER // 4, (ksize, ksize), padding = \"same\", activation = \"relu\")(b2c2)\nb2c4 = layers.Conv2D(FILTER // 4, (ksize, ksize), padding = \"same\", activation = \"relu\")(b2c3)\n\nmp2 = layers.MaxPool2D((2, 2))(b2c4)\n\nb3c1 = layers.Conv2D(FILTER // 2, (ksize, ksize), padding = \"same\", activation = \"relu\")(mp2)\nb3c2 = layers.Conv2D(FILTER // 2, (ksize, ksize), padding = \"same\", activation = \"relu\")(b3c1)\nb3c3 = layers.Conv2D(FILTER // 2, (ksize, ksize), padding = \"same\", activation = \"relu\")(b3c2)\nb3c4 = layers.Conv2D(FILTER // 2, (ksize, ksize), padding = \"same\", activation = \"relu\")(b3c3)\n\nmp3 = layers.MaxPool2D((2, 2))(b3c4)\n\nb4c1 = layers.Conv2D(FILTER, (ksize, ksize), padding = \"same\", activation = \"relu\")(mp3)\nb4c2 = layers.Conv2D(FILTER, (ksize, ksize), padding = \"same\", activation = \"relu\")(b4c1)\n\nx = layers.Conv2DTranspose(FILTER, (ksize, ksize), padding = \"same\", activation = \"relu\")(b4c2)\nb4c3 = layers.add([x, b4c2])\n\nx = layers.Conv2DTranspose(FILTER, (ksize, ksize), padding = \"same\", activation = \"relu\")(b4c3)\nb4c4 = layers.add([x, b4c1])\n\nus1 = layers.UpSampling2D((2, 2))(b4c4)\n\nx = layers.Conv2DTranspose(FILTER // 2, (ksize, ksize), padding = \"same\", activation = \"relu\")(us1)\nb5c1 = layers.add([x, b3c4])\nx = layers.Conv2DTranspose(FILTER // 2, (ksize, ksize), padding = \"same\", activation = \"relu\")(b5c1)\nb5c2 = layers.add([x, b3c3])\nx = layers.Conv2DTranspose(FILTER // 2, (ksize, ksize), padding = \"same\", activation = \"relu\")(b5c2)\nb5c3 = layers.add([x, b3c2])\nx = layers.Conv2DTranspose(FILTER // 2, (ksize, ksize), padding = \"same\", activation = \"relu\")(b5c3)\nb5c4 = layers.add([x, b3c1])\n\nus2 = layers.UpSampling2D((2, 2))(b5c4)\n\nx = layers.Conv2DTranspose(FILTER // 4, (ksize, ksize), padding = \"same\", activation = \"relu\")(us2)\nb6c1 = layers.add([x, b2c4])\nx = layers.Conv2DTranspose(FILTER // 4, (ksize, ksize), padding = \"same\", activation = \"relu\")(b6c1)\nb6c2 = layers.add([x, b2c3])\nx = layers.Conv2DTranspose(FILTER // 4, (ksize, ksize), padding = \"same\", activation = \"relu\")(b6c2)\nb6c3 = layers.add([x, b2c2])\nx = layers.Conv2DTranspose(FILTER // 4, (ksize, ksize), padding = \"same\", activation = \"relu\")(b6c3)\nb6c4 = layers.add([x, b2c1])\n\nus3 = layers.UpSampling2D((2, 2))(b6c4)\n\nx = layers.Conv2DTranspose(FILTER // 8, (ksize, ksize), padding = \"same\", activation = \"relu\")(us3)\nb7c1 = layers.add([x, b1c4])\nx = layers.Conv2DTranspose(FILTER // 8, (ksize, ksize), padding = \"same\", activation = \"relu\")(b7c1)\nb7c2 = layers.add([x, b1c3])\nx = layers.Conv2DTranspose(FILTER // 8, (ksize, ksize), padding = \"same\", activation = \"relu\")(b7c2)\nb7c3 = layers.add([x, b1c2])\nx = layers.Conv2DTranspose(FILTER // 8, (ksize, ksize), padding = \"same\", activation = \"relu\")(b7c3)\nb7c4 = layers.add([x, b1c1])\n\nb8c1 = layers.Conv2DTranspose(FILTER // 16, (ksize, ksize), padding = \"same\", activation = \"relu\")(b7c4)\nb8c2 = layers.Conv2DTranspose(FILTER // 16, (ksize, ksize), padding = \"same\", activation = \"relu\")(b8c1)\noutputs = layers.Conv2DTranspose(CHANNELS, (ksize, ksize), padding = \"same\", activation = \"relu\")(b8c2)\n\nautoencoder = Model(inputs=inputs, outputs=outputs, name=\"AE\")\n\n#autoencoder.compile(optimizer=opt, loss=losses.MeanAbsoluteError())\n\n#autoencoder.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = tf.keras.Input(shape=(None, None, CHANNELS))\n\nc0 = layers.Conv2D(FILTER // 4, (ksize, ksize), padding = \"same\", activation = \"relu\")(inputs)\nc1 = layers.Conv2D(FILTER // 4, (ksize, ksize), padding = \"same\", activation = \"relu\")(c0)\nc2 = layers.Conv2D(FILTER // 4, (ksize, ksize), padding = \"same\", activation = \"relu\")(c1)\n\na = layers.add([c0, c2])\n\nfor i in range(3):\n    x = layers.Conv2D(FILTER // 4, (ksize, ksize), padding = \"same\", activation = \"relu\")(a)\n    x = layers.Conv2D(FILTER // 4, (ksize, ksize), padding = \"same\", activation = \"relu\")(x)\n\n    a = layers.add([a, x])\n\nc7 = layers.Conv2D(FILTER // 4, (ksize, ksize), padding = \"same\", activation = \"relu\")(a)\noutputs = layers.Conv2D(CHANNELS, (ksize, ksize), padding = \"same\", activation = \"relu\")(c7)\n\nresnet = Model(inputs=inputs, outputs=outputs, name=\"RN\")\n\n#resnet.compile(optimizer=opt, loss=losses.MeanAbsoluteError())\n#resnet.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = tf.keras.Input(shape=(None, None, CHANNELS))\n\nb1s1c1 = layers.Conv2D(4, (1, 1), padding = \"same\", activation = \"relu\")(inputs)\n\nb1s2c1 = layers.Conv2D(4, (1, 1), padding = \"same\", activation = \"relu\")(inputs)\nb1s2c2 = layers.Conv2D(4, (3, 3), padding = \"same\", activation = \"relu\")(b1s2c1)\n\nb1s3c1 = layers.Conv2D(4, (1, 1), padding = \"same\", activation = \"relu\")(inputs)\nb1s3c2 = layers.Conv2D(4, (5, 5), padding = \"same\", activation = \"relu\")(b1s3c1)\n\nconcat1 = layers.concatenate([b1s1c1, b1s2c2, b1s3c2])\n\n\nb2s1c1 = layers.Conv2D(8, (1, 1), padding = \"same\", activation = \"relu\")(concat1)\n\nb2s2c1 = layers.Conv2D(8, (1, 1), padding = \"same\", activation = \"relu\")(concat1)\nb2s2c2 = layers.Conv2D(8, (3, 3), padding = \"same\", activation = \"relu\")(b2s2c1)\n\nb2s3c1 = layers.Conv2D(8, (1, 1), padding = \"same\", activation = \"relu\")(concat1)\nb2s3c2 = layers.Conv2D(8, (5, 5), padding = \"same\", activation = \"relu\")(b2s3c1)\n\nconcat2 = layers.concatenate([b2s1c1, b2s2c2, b2s3c2])\n\n\nb3s1c1 = layers.Conv2D(8, (1, 1), padding = \"same\", activation = \"relu\")(concat2)\n\nb3s2c1 = layers.Conv2D(8, (1, 1), padding = \"same\", activation = \"relu\")(concat2)\nb3s2c2 = layers.Conv2D(8, (3, 3), padding = \"same\", activation = \"relu\")(b3s2c1)\n\nb3s3c1 = layers.Conv2D(8, (1, 1), padding = \"same\", activation = \"relu\")(concat2)\nb3s3c2 = layers.Conv2D(8, (5, 5), padding = \"same\", activation = \"relu\")(b3s3c1)\n\nconcat3 = layers.concatenate([b3s1c1, b3s2c2, b3s3c2])\n\n\nb4s1c1 = layers.Conv2D(4, (1, 1), padding = \"same\", activation = \"relu\")(concat3)\n\nb4s2c1 = layers.Conv2D(4, (1, 1), padding = \"same\", activation = \"relu\")(concat3)\nb4s2c2 = layers.Conv2D(4, (3, 3), padding = \"same\", activation = \"relu\")(b4s2c1)\n\nb4s3c1 = layers.Conv2D(4, (1, 1), padding = \"same\", activation = \"relu\")(concat3)\nb4s3c2 = layers.Conv2D(4, (5, 5), padding = \"same\", activation = \"relu\")(b4s3c1)\n\nconcat4 = layers.concatenate([b4s1c1, b4s2c2, b4s3c2])\n\n\noutputs = layers.Conv2D(CHANNELS, (ksize, ksize), padding = \"same\", activation = \"relu\")(concat3)\n\ninception = Model(inputs=inputs, outputs=outputs, name=\"IN\")\n#inception.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = tf.keras.Input(shape=(None, None, CHANNELS))\n\ndb1c1 = layers.Conv2D(FILTER // 8, (ksize, ksize), padding = \"same\", activation = \"relu\")(inputs)\ndb1c2 = layers.Conv2D(FILTER // 8, (ksize, ksize), padding = \"same\", activation = \"relu\")(db1c1)\ndmp1 = layers.MaxPool2D((2, 2))(db1c2)\n\ndb2c1 = layers.Conv2D(FILTER // 4, (ksize, ksize), padding = \"same\", activation = \"relu\")(dmp1)\ndb2c2 = layers.Conv2D(FILTER // 4, (ksize, ksize), padding = \"same\", activation = \"relu\")(db2c1)\ndmp2 = layers.MaxPool2D((2, 2))(db2c2)\n\ndb3c1 = layers.Conv2D(FILTER // 2, (ksize, ksize), padding = \"same\", activation = \"relu\")(dmp2)\ndb3c2 = layers.Conv2D(FILTER // 2, (ksize, ksize), padding = \"same\", activation = \"relu\")(db3c1)\ndmp3 = layers.MaxPool2D((2, 2))(db3c2)\n\ndb4c1 = layers.Conv2D(FILTER, (ksize, ksize), padding = \"same\", activation = \"relu\")(dmp3)\ndb4c2 = layers.Conv2D(FILTER, (ksize, ksize), padding = \"same\", activation = \"relu\")(db4c1)\ndmp4 = layers.MaxPool2D((2, 2))(db4c2)\n\noutputs = layers.Dense(1, activation = \"sigmoid\")(dmp4)\n\ndiscriminator = Model(inputs=inputs, outputs=outputs, name=\"DC\")\nopt = tf.keras.optimizers.Adam()\n\n#discriminator.compile(optimizer=opt, loss=losses.MeanSquaredError())\n#discriminator.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot_model(inception, show_shapes=True, show_layer_names=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds = tf.data.Dataset.list_files(ffhq_path, shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_image_downscale(file_path):\n    \n    img = tf.io.read_file(file_path)\n    img = tf.image.decode_jpeg(img)\n    img = img / 255\n    \n    img_d = img[::SCALE, ::SCALE]\n    img_d = tf.image.resize(img_d, [512, 512])\n    \n    return img_d, img","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_image_noisy(file_path):\n    \n    img = tf.io.read_file(file_path)\n    img = tf.image.decode_jpeg(img)\n    img = img / 255\n    \n    return img","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds2 = ds.map(process_image_downscale)\nds2 = ds2.batch(32)\nds2 = ds2.take(1000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for step, (x, y) in enumerate(ds2):\n    \n    plt.imshow(x[0])\n    plt.show()\n    #x = tf.clip_by_value(x + tf.random.normal(x.shape, stddev=0.4), 0, 1)\n    plt.imshow(y[0])\n    plt.show()\n    \n    break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\nloss_fn = tf.keras.losses.MeanAbsoluteError()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 3\n\nfor epoch in range(epochs):\n    print(f\"Start of epoch {epoch + 1}\")\n    start_time = time.perf_counter()\n    \n    for step, (x_batch_train) in enumerate(ds2):\n        \n        with tf.GradientTape() as tape:\n            logits = resnet(tf.clip_by_value(\n                                 x_batch_train + tf.random.normal(x_batch_train.shape, stddev=0.4),\n                                 0, 1), training=True)\n            loss_value = loss_fn(x_batch_train, logits)\n            \n        grads = tape.gradient(loss_value, resnet.trainable_weights)\n        optimizer.apply_gradients(zip(grads, resnet.trainable_weights))\n        \n        if (step + 1) % 100 == 0:\n            print(\"Training loss at step %d: %.4f\"% (step + 1, float(loss_value)))\n            print(f\"{int(time.perf_counter() - start_time)} s\")\n            start_time = time.perf_counter()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 3\n\nfor epoch in range(epochs):\n    print(f\"Start of epoch {epoch + 1}\")\n    start_time = time.perf_counter()\n    \n    for step, (x_batch_train, y_batch_train) in enumerate(ds2):\n        \n        with tf.GradientTape() as tape:\n            logits = resnet(x_batch_train, training=True)\n            loss_value = loss_fn(y_batch_train, logits)\n            \n        grads = tape.gradient(loss_value, resnet.trainable_weights)\n        optimizer.apply_gradients(zip(grads, resnet.trainable_weights))\n        \n        if (step + 1) % 100 == 0:\n            print(\"Training loss at step %d: %.4f\"% (step + 1, float(loss_value)))\n            print(f\"{int(time.perf_counter() - start_time)} s\")\n            start_time = time.perf_counter()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count = 5\n\nplt.figure(figsize=(15, 7 * count))\n\nstart = 40000\n\nfor n in range(start, start + count):\n    \n    test_path = f\"{ffhq_path[:-1]}{n:05d}.png\"\n    \n    test_img = cv2.imread(test_path)[:,:,::-1]\n    test_img = test_img.reshape(-1 , 512, 512, CHANNELS)\n    test_img = test_img / 255.\n    \n    test_img_noisy = tf.clip_by_value(test_img + tf.random.normal(test_img.shape,stddev=0.4), 0, 1).numpy()\n    \n    predict = resnet(test_img_noisy.reshape(-1, 512, 512, CHANNELS)).numpy()\n    \n    psnr_down = peak_signal_noise_ratio(test_img, test_img_noisy.astype('float32'))\n    mae_down = loss_fn(test_img, test_img_noisy)\n    ssim_down = structural_similarity(test_img[0], test_img_noisy[0], multichannel=True)\n    \n    psnr = peak_signal_noise_ratio(test_img, predict)\n    mae = loss_fn(test_img, predict)\n    ssim = structural_similarity(test_img[0], predict[0], multichannel=True)\n    \n    plt.subplot(count, 3, 1 + 3 * (n - start))\n    plt.title(f\"Noisy\\nPSNR: {psnr_down:.2f} db\\nMAE: {mae_down:.5f}\\nSSIM: {ssim_down:.2f}\")\n    plt.axis(\"off\")\n    plt.imshow(test_img_noisy[0])\n    \n    plt.subplot(count, 3, 2 + 3 * (n - start))\n    plt.title(f\"Denoised\\nPSNR: {psnr:.2f} db\\nMAE: {mae:.5f}\\nSSIM: {ssim:.2f}\")\n    plt.axis(\"off\")\n    plt.imshow(predict[0])\n    \n    plt.subplot(count, 3, 3 + 3 * (n - start))\n    plt.title(\"Ground Truth\")\n    plt.axis(\"off\")\n    plt.imshow(test_img[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count = 5\n\nplt.figure(figsize=(15, 7 * count))\n\nstart = 40000\nSCALE = 8\n\nfor n in range(start, start + count):\n    \n    test_path = f\"{ffhq_path[:-1]}{n:05d}.png\"\n    \n    test_img = cv2.imread(test_path)[:,:,::-1]\n    test_img = test_img.reshape(-1 , 512, 512, CHANNELS)\n    test_img = test_img / 255.\n    \n    test_img_down = resize(test_img[:, ::SCALE, ::SCALE, :],  (1, 512, 512, CHANNELS))\n    \n    test_img_down_pix = test_img[:, ::SCALE, ::SCALE, :]\n    \n    predict = resnet(test_img_down.reshape(-1, 512, 512, CHANNELS)).numpy()\n    \n    psnr_down = peak_signal_noise_ratio(test_img, test_img_down.astype('float32'))\n    mae_down = loss_fn(test_img, test_img_down)\n    ssim_down = structural_similarity(test_img[0], test_img_down[0], multichannel=True)\n    \n    psnr = peak_signal_noise_ratio(test_img, predict)\n    mae = loss_fn(test_img, predict)\n    ssim = structural_similarity(test_img[0], predict[0], multichannel=True)\n    \n    plt.subplot(count, 3, 1 + 3 * (n - start))\n    plt.title(f\"Low Res\\nPSNR: {psnr_down:.2f} db\\nMAE: {mae_down:.5f}\\nSSIM: {ssim_down:.2f}\")\n    plt.axis(\"off\")\n    plt.imshow(test_img_down_pix[0])\n    \n    plt.subplot(count, 3, 2 + 3 * (n - start))\n    plt.title(f\"{SCALE}x Upscaled\\nPSNR: {psnr:.2f} db\\nMAE: {mae:.5f}\\nSSIM: {ssim:.2f}\")\n    plt.axis(\"off\")\n    plt.imshow(predict[0])\n    \n    plt.subplot(count, 3, 3 + 3 * (n - start))\n    plt.title(\"Ground Truth\")\n    plt.axis(\"off\")\n    plt.imshow(test_img[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet.save(\"Resnet Upscale.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}